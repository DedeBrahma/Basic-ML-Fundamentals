{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN Classification (NBA 2013).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOZ4lAYn25LbyCgpROy+ytA"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHMY7yH4o0K7",
        "colab_type": "text"
      },
      "source": [
        "Reference:\n",
        "\n",
        "https://www.dataquest.io/blog/k-nearest-neighbors-in-python/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMBDeAWGpwT4",
        "colab_type": "text"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TrEHA-Mp22J",
        "colab_type": "text"
      },
      "source": [
        "Before we dive into the algorithm, let’s take a look at our data. Each row in the data contains information on how a player performed in the 2013-2014 NBA season.\n",
        "\n",
        "Here are some selected columns from the data:\n",
        "\n",
        "\n",
        "\n",
        "*   player — name of the player\n",
        "*   pos — the position of the player\n",
        "*   g — number of games the player was in\n",
        "*   gs — number of games the player started\n",
        "*   pts — total points the player scored"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKCKeLlkoi4n",
        "colab_type": "code",
        "outputId": "792d8365-6ee3-4e66-e464-138071869060",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import pandas\n",
        "with open(\"./sample_data/nba_2013.csv\", 'r') as csvfile:\n",
        "    nba = pandas.read_csv(csvfile)\n",
        "print(nba.columns.values)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['player' 'pos' 'age' 'bref_team_id' 'g' 'gs' 'mp' 'fg' 'fga' 'fg.' 'x3p'\n",
            " 'x3pa' 'x3p.' 'x2p' 'x2pa' 'x2p.' 'efg.' 'ft' 'fta' 'ft.' 'orb' 'drb'\n",
            " 'trb' 'ast' 'stl' 'blk' 'tov' 'pf' 'pts' 'season' 'season_end']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7jB70-Ap7E5",
        "colab_type": "text"
      },
      "source": [
        "# Euclidean distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqPMCNiUp_nW",
        "colab_type": "text"
      },
      "source": [
        "Before we can predict using KNN, we need to find some way to figure out which data rows are “closest” to the row we’re trying to predict on.\n",
        "\n",
        "A simple way to do this is to use Euclidean distance. The formula is \n",
        "\n",
        "![alt text](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fwww.machinelearningplus.com%2Fwp-content%2Fuploads%2F2019%2F04%2F2_multivariate_euclidean_distance_formula-min.png&f=1&nofb=1https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fwww.machinelearningplus.com%2Fwp-content%2Fuploads%2F2019%2F04%2F2_multivariate_euclidean_distance_formula-min.png&f=1&nofb=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Hvjau1ppo8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "nba = nba.dropna()\n",
        "\n",
        "# Select Lebron James from our dataset\n",
        "selected_player = nba[nba[\"player\"] == \"LeBron James\"].iloc[0]\n",
        "\n",
        "# Choose only the numeric columns (we'll use these to compute euclidean distance)\n",
        "distance_columns = ['age', 'g', 'gs', 'mp', 'fg', 'fga', 'fg.', 'x3p', 'x3pa', 'x3p.', 'x2p', 'x2pa', 'x2p.', 'efg.', 'ft', 'fta', 'ft.', 'orb', 'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf', 'pts']\n",
        "\n",
        "def euclidean_distance(row):\n",
        "    \"\"\"\n",
        "    A simple euclidean distance function\n",
        "    \"\"\"\n",
        "    inner_value = 0\n",
        "    for k in distance_columns:\n",
        "      inner_value += (row[k] - selected_player[k]) ** 2\n",
        "      return math.sqrt(inner_value)\n",
        "\n",
        "# Find the distance from each player in the dataset to lebron.\n",
        "lebron_distance = nba.apply(euclidean_distance, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZQ5-VcVtouA",
        "colab_type": "code",
        "outputId": "b592ae3a-eb7d-48bf-f0e3-4886a18caf97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "lebron_distance"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      6.0\n",
              "3      1.0\n",
              "4      4.0\n",
              "6      1.0\n",
              "7      5.0\n",
              "      ... \n",
              "476    9.0\n",
              "477    1.0\n",
              "478    4.0\n",
              "479    8.0\n",
              "480    5.0\n",
              "Length: 403, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8DR-AGdsKV8",
        "colab_type": "text"
      },
      "source": [
        "# Normalizing columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcryemdksO8K",
        "colab_type": "text"
      },
      "source": [
        "A simple way to deal with this is to normalize all the columns to have a mean of 0, and a standard deviation of 1. This will ensure that no single column has a dominant impact on the euclidean distance calculations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB09XspNsETC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select only the numeric columns from the NBA dataset\n",
        "nba_numeric = nba[distance_columns]\n",
        "# Normalize all of the numeric columns\n",
        "nba_normalized = (nba_numeric - nba_numeric.mean()) / nba_numeric.std()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zvyufh9mtsQk",
        "colab_type": "code",
        "outputId": "2cd47c7c-c6a9-419d-ba58-5f92a79dd078",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "nba_normalized"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>g</th>\n",
              "      <th>gs</th>\n",
              "      <th>mp</th>\n",
              "      <th>fg</th>\n",
              "      <th>fga</th>\n",
              "      <th>fg.</th>\n",
              "      <th>x3p</th>\n",
              "      <th>x3pa</th>\n",
              "      <th>x3p.</th>\n",
              "      <th>x2p</th>\n",
              "      <th>x2pa</th>\n",
              "      <th>x2p.</th>\n",
              "      <th>efg.</th>\n",
              "      <th>ft</th>\n",
              "      <th>fta</th>\n",
              "      <th>ft.</th>\n",
              "      <th>orb</th>\n",
              "      <th>drb</th>\n",
              "      <th>trb</th>\n",
              "      <th>ast</th>\n",
              "      <th>stl</th>\n",
              "      <th>blk</th>\n",
              "      <th>tov</th>\n",
              "      <th>pf</th>\n",
              "      <th>pts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.814777</td>\n",
              "      <td>0.235407</td>\n",
              "      <td>-0.944580</td>\n",
              "      <td>-0.613829</td>\n",
              "      <td>-0.877328</td>\n",
              "      <td>-0.925592</td>\n",
              "      <td>0.482473</td>\n",
              "      <td>-0.826813</td>\n",
              "      <td>-0.859228</td>\n",
              "      <td>-0.115785</td>\n",
              "      <td>-0.723659</td>\n",
              "      <td>-0.753777</td>\n",
              "      <td>0.320007</td>\n",
              "      <td>-0.010073</td>\n",
              "      <td>-0.637683</td>\n",
              "      <td>-0.607244</td>\n",
              "      <td>-0.589593</td>\n",
              "      <td>0.233644</td>\n",
              "      <td>-0.225131</td>\n",
              "      <td>-0.090114</td>\n",
              "      <td>-0.763546</td>\n",
              "      <td>-0.624501</td>\n",
              "      <td>0.044941</td>\n",
              "      <td>-0.803874</td>\n",
              "      <td>0.102809</td>\n",
              "      <td>-0.874569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.352916</td>\n",
              "      <td>0.676249</td>\n",
              "      <td>1.455748</td>\n",
              "      <td>1.338616</td>\n",
              "      <td>1.426921</td>\n",
              "      <td>1.432458</td>\n",
              "      <td>0.359705</td>\n",
              "      <td>1.545983</td>\n",
              "      <td>1.248019</td>\n",
              "      <td>0.935220</td>\n",
              "      <td>1.106739</td>\n",
              "      <td>1.203540</td>\n",
              "      <td>0.075030</td>\n",
              "      <td>0.532970</td>\n",
              "      <td>1.582841</td>\n",
              "      <td>1.478015</td>\n",
              "      <td>0.519979</td>\n",
              "      <td>-0.412605</td>\n",
              "      <td>0.375022</td>\n",
              "      <td>0.142778</td>\n",
              "      <td>0.864779</td>\n",
              "      <td>-0.279742</td>\n",
              "      <td>-0.705609</td>\n",
              "      <td>1.028200</td>\n",
              "      <td>0.306263</td>\n",
              "      <td>1.568399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.347700</td>\n",
              "      <td>-0.073182</td>\n",
              "      <td>0.041856</td>\n",
              "      <td>-0.494735</td>\n",
              "      <td>-0.472058</td>\n",
              "      <td>-0.632869</td>\n",
              "      <td>1.546458</td>\n",
              "      <td>-0.903355</td>\n",
              "      <td>-0.962741</td>\n",
              "      <td>-1.867461</td>\n",
              "      <td>-0.229318</td>\n",
              "      <td>-0.345585</td>\n",
              "      <td>1.027974</td>\n",
              "      <td>0.858795</td>\n",
              "      <td>-0.442574</td>\n",
              "      <td>-0.504087</td>\n",
              "      <td>0.670309</td>\n",
              "      <td>0.589081</td>\n",
              "      <td>0.047031</td>\n",
              "      <td>0.218722</td>\n",
              "      <td>-0.674728</td>\n",
              "      <td>-0.624501</td>\n",
              "      <td>0.697593</td>\n",
              "      <td>-0.282680</td>\n",
              "      <td>1.047417</td>\n",
              "      <td>-0.543641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.352916</td>\n",
              "      <td>0.499912</td>\n",
              "      <td>1.324224</td>\n",
              "      <td>1.276779</td>\n",
              "      <td>2.515361</td>\n",
              "      <td>2.549144</td>\n",
              "      <td>0.346064</td>\n",
              "      <td>-0.845948</td>\n",
              "      <td>-0.859228</td>\n",
              "      <td>-0.553704</td>\n",
              "      <td>3.197668</td>\n",
              "      <td>3.535591</td>\n",
              "      <td>-0.071235</td>\n",
              "      <td>-0.322322</td>\n",
              "      <td>1.787240</td>\n",
              "      <td>1.654856</td>\n",
              "      <td>0.570089</td>\n",
              "      <td>1.752328</td>\n",
              "      <td>2.950097</td>\n",
              "      <td>2.689410</td>\n",
              "      <td>0.346676</td>\n",
              "      <td>0.524695</td>\n",
              "      <td>1.415510</td>\n",
              "      <td>0.664944</td>\n",
              "      <td>0.466120</td>\n",
              "      <td>2.143835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-0.581239</td>\n",
              "      <td>0.323576</td>\n",
              "      <td>-0.878818</td>\n",
              "      <td>-0.356175</td>\n",
              "      <td>-0.483638</td>\n",
              "      <td>-0.494638</td>\n",
              "      <td>0.196015</td>\n",
              "      <td>-0.865084</td>\n",
              "      <td>-0.874015</td>\n",
              "      <td>-0.856879</td>\n",
              "      <td>-0.256039</td>\n",
              "      <td>-0.215097</td>\n",
              "      <td>-0.083895</td>\n",
              "      <td>-0.444506</td>\n",
              "      <td>-0.656264</td>\n",
              "      <td>-0.629350</td>\n",
              "      <td>-0.589593</td>\n",
              "      <td>0.992986</td>\n",
              "      <td>0.109838</td>\n",
              "      <td>0.390860</td>\n",
              "      <td>-0.445282</td>\n",
              "      <td>-0.595771</td>\n",
              "      <td>0.273369</td>\n",
              "      <td>-0.582761</td>\n",
              "      <td>0.160939</td>\n",
              "      <td>-0.596336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>476</th>\n",
              "      <td>-1.515393</td>\n",
              "      <td>0.632165</td>\n",
              "      <td>-0.418481</td>\n",
              "      <td>0.437399</td>\n",
              "      <td>0.737962</td>\n",
              "      <td>0.882246</td>\n",
              "      <td>-0.076802</td>\n",
              "      <td>-0.137937</td>\n",
              "      <td>0.419908</td>\n",
              "      <td>-0.469847</td>\n",
              "      <td>0.899650</td>\n",
              "      <td>0.899068</td>\n",
              "      <td>0.318398</td>\n",
              "      <td>-0.417354</td>\n",
              "      <td>0.978933</td>\n",
              "      <td>1.404330</td>\n",
              "      <td>-0.725605</td>\n",
              "      <td>0.185175</td>\n",
              "      <td>-0.120453</td>\n",
              "      <td>-0.029360</td>\n",
              "      <td>0.635333</td>\n",
              "      <td>0.955644</td>\n",
              "      <td>-0.281385</td>\n",
              "      <td>1.944236</td>\n",
              "      <td>0.524249</td>\n",
              "      <td>0.744240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>477</th>\n",
              "      <td>0.352916</td>\n",
              "      <td>0.279491</td>\n",
              "      <td>-0.648649</td>\n",
              "      <td>0.488930</td>\n",
              "      <td>0.981124</td>\n",
              "      <td>1.101789</td>\n",
              "      <td>0.032325</td>\n",
              "      <td>1.679931</td>\n",
              "      <td>1.617712</td>\n",
              "      <td>0.666213</td>\n",
              "      <td>0.545595</td>\n",
              "      <td>0.628055</td>\n",
              "      <td>0.011661</td>\n",
              "      <td>0.383633</td>\n",
              "      <td>1.220496</td>\n",
              "      <td>1.102226</td>\n",
              "      <td>0.591565</td>\n",
              "      <td>-0.461074</td>\n",
              "      <td>-0.273981</td>\n",
              "      <td>-0.343259</td>\n",
              "      <td>-0.267647</td>\n",
              "      <td>0.036287</td>\n",
              "      <td>-0.411916</td>\n",
              "      <td>0.222719</td>\n",
              "      <td>0.596911</td>\n",
              "      <td>1.176344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>478</th>\n",
              "      <td>-0.347700</td>\n",
              "      <td>0.940754</td>\n",
              "      <td>1.620154</td>\n",
              "      <td>1.528707</td>\n",
              "      <td>2.110091</td>\n",
              "      <td>2.169687</td>\n",
              "      <td>0.291501</td>\n",
              "      <td>0.818836</td>\n",
              "      <td>1.188868</td>\n",
              "      <td>0.157164</td>\n",
              "      <td>2.148863</td>\n",
              "      <td>2.140375</td>\n",
              "      <td>0.375373</td>\n",
              "      <td>0.084960</td>\n",
              "      <td>0.551552</td>\n",
              "      <td>0.689595</td>\n",
              "      <td>-0.217349</td>\n",
              "      <td>1.752328</td>\n",
              "      <td>0.933304</td>\n",
              "      <td>1.226236</td>\n",
              "      <td>0.376281</td>\n",
              "      <td>3.512605</td>\n",
              "      <td>0.371267</td>\n",
              "      <td>1.328280</td>\n",
              "      <td>1.425260</td>\n",
              "      <td>1.751780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>479</th>\n",
              "      <td>-1.281855</td>\n",
              "      <td>1.073007</td>\n",
              "      <td>-0.845937</td>\n",
              "      <td>0.037749</td>\n",
              "      <td>-0.263634</td>\n",
              "      <td>-0.212757</td>\n",
              "      <td>-0.090442</td>\n",
              "      <td>-0.903355</td>\n",
              "      <td>-0.962741</td>\n",
              "      <td>-1.867461</td>\n",
              "      <td>0.011172</td>\n",
              "      <td>0.173021</td>\n",
              "      <td>-0.500343</td>\n",
              "      <td>-0.770332</td>\n",
              "      <td>0.393606</td>\n",
              "      <td>0.475911</td>\n",
              "      <td>-0.088496</td>\n",
              "      <td>0.976830</td>\n",
              "      <td>0.409915</td>\n",
              "      <td>0.603501</td>\n",
              "      <td>-0.289851</td>\n",
              "      <td>-0.136093</td>\n",
              "      <td>0.534430</td>\n",
              "      <td>0.096369</td>\n",
              "      <td>0.800365</td>\n",
              "      <td>-0.202173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>480</th>\n",
              "      <td>-0.581239</td>\n",
              "      <td>0.543997</td>\n",
              "      <td>-0.648649</td>\n",
              "      <td>-0.382513</td>\n",
              "      <td>-0.356267</td>\n",
              "      <td>-0.521742</td>\n",
              "      <td>1.437331</td>\n",
              "      <td>-0.903355</td>\n",
              "      <td>-0.962741</td>\n",
              "      <td>-1.867461</td>\n",
              "      <td>-0.095712</td>\n",
              "      <td>-0.208405</td>\n",
              "      <td>0.919942</td>\n",
              "      <td>0.750187</td>\n",
              "      <td>-0.154556</td>\n",
              "      <td>-0.106193</td>\n",
              "      <td>-0.167240</td>\n",
              "      <td>0.734486</td>\n",
              "      <td>0.019117</td>\n",
              "      <td>0.244036</td>\n",
              "      <td>-0.704334</td>\n",
              "      <td>-0.768151</td>\n",
              "      <td>0.436532</td>\n",
              "      <td>-0.330062</td>\n",
              "      <td>0.320795</td>\n",
              "      <td>-0.393985</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>403 rows × 26 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          age         g        gs  ...       tov        pf       pts\n",
              "0   -0.814777  0.235407 -0.944580  ... -0.803874  0.102809 -0.874569\n",
              "3    0.352916  0.676249  1.455748  ...  1.028200  0.306263  1.568399\n",
              "4   -0.347700 -0.073182  0.041856  ... -0.282680  1.047417 -0.543641\n",
              "6    0.352916  0.499912  1.324224  ...  0.664944  0.466120  2.143835\n",
              "7   -0.581239  0.323576 -0.878818  ... -0.582761  0.160939 -0.596336\n",
              "..        ...       ...       ...  ...       ...       ...       ...\n",
              "476 -1.515393  0.632165 -0.418481  ...  1.944236  0.524249  0.744240\n",
              "477  0.352916  0.279491 -0.648649  ...  0.222719  0.596911  1.176344\n",
              "478 -0.347700  0.940754  1.620154  ...  1.328280  1.425260  1.751780\n",
              "479 -1.281855  1.073007 -0.845937  ...  0.096369  0.800365 -0.202173\n",
              "480 -0.581239  0.543997 -0.648649  ... -0.330062  0.320795 -0.393985\n",
              "\n",
              "[403 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnWUFUHgsVO-",
        "colab_type": "text"
      },
      "source": [
        "# Finding the nearest neighbor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yImcRHBsYlY",
        "colab_type": "text"
      },
      "source": [
        "We now know enough to find the nearest neighbor of a given row in the NBA dataset. We can use the distance.euclidean function from scipy.spatial, a much faster way to calculate euclidean distance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odkTCFPLsZW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.spatial import distance\n",
        "\n",
        "# Fill in NA values in nba_normalized\n",
        "nba_normalized.fillna(0, inplace=True)\n",
        "\n",
        "# Find the normalized vector for lebron james.\n",
        "lebron_normalized = nba_normalized[nba[\"player\"] == \"LeBron James\"]\n",
        "\n",
        "# Find the distance between lebron james and everyone else.\n",
        "euclidean_distances = nba_normalized.apply(lambda row: distance.euclidean(row, lebron_normalized), axis=1)\n",
        "\n",
        "# Create a new dataframe with distances.\n",
        "distance_frame = pandas.DataFrame(data={\"dist\": euclidean_distances, \"idx\": euclidean_distances.index})\n",
        "distance_frame.sort_values(\"dist\", inplace=True)\n",
        "# Find the most similar player to lebron (the lowest distance to lebron is lebron, the second smallest is the most similar non-lebron player)\n",
        "second_smallest = distance_frame.iloc[1][\"idx\"]\n",
        "most_similar_to_lebron = nba.loc[int(second_smallest)][\"player\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVyiRDsEs25d",
        "colab_type": "text"
      },
      "source": [
        "# Generating training and testing sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq_fJRjqtBA8",
        "colab_type": "text"
      },
      "source": [
        "Now that we know how to find the nearest neighbors, we can make predictions on a test set. We’ll try to predict how many points a player scored using the 5 closest neighbors. We’ll find neighbors by using all the numeric columns in the dataset to generate similarity scores.\n",
        "\n",
        "First, we have to generate test and train sets. In order to do this, we’ll use random sampling. We’ll randomly shuffle the index of the nba dataframe, and then pick rows using the randomly shuffled values.\n",
        "\n",
        "If we didn’t do this, we’d end up predicting and training on the same data set, which would overfit. We could do cross validation also, which would be slightly better, but slightly more complex."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBOH0EmEtCRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "from numpy.random import permutation\n",
        "\n",
        "# Randomly shuffle the index of nba.\n",
        "random_indices = permutation(nba.index)\n",
        "\n",
        "# Set a cutoff for how many items we want in the test set (in this case 1/3 of the items)\n",
        "test_cutoff = math.floor(len(nba)/3)\n",
        "\n",
        "# Generate the test set by taking the first 1/3 of the randomly shuffled indices.\n",
        "test = nba.loc[random_indices[1:test_cutoff]]\n",
        "\n",
        "# Generate the train set with the rest of the data.\n",
        "train = nba.loc[random_indices[test_cutoff:]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjYgjlBztF5H",
        "colab_type": "text"
      },
      "source": [
        "# Using sklearn for k nearest neighbors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2-aMEWKtK8W",
        "colab_type": "text"
      },
      "source": [
        "There’s a regressor and a classifier available, but we’ll be using the regressor, as we have continuous values to predict on.\n",
        "\n",
        "Sklearn performs the normalization and distance finding automatically"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVw3giAktLtG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The columns that we will be making predictions with.\n",
        "x_columns = ['age', 'g', 'gs', 'mp', 'fg', 'fga', 'fg.', 'x3p', 'x3pa', 'x3p.', 'x2p', 'x2pa', 'x2p.', 'efg.', 'ft', 'fta', 'ft.', 'orb', 'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf']\n",
        "# The column that we want to predict.\n",
        "y_column = [\"pts\"]\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "# Create the knn model.\n",
        "# Look at the five closest neighbors.\n",
        "knn = KNeighborsRegressor(n_neighbors=5)\n",
        "# Fit the model on the training data.\n",
        "knn.fit(train[x_columns], train[y_column])\n",
        "# Make point predictions on the test set using the fit model.\n",
        "predictions = knn.predict(test[x_columns])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SblkSqEE0dlQ",
        "colab_type": "code",
        "outputId": "e2692829-e80b-48c3-b13f-86b0fc062033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "predictions"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 400.6],\n",
              "       [ 114. ],\n",
              "       [  30. ],\n",
              "       [ 831.4],\n",
              "       [ 780. ],\n",
              "       [ 941.2],\n",
              "       [ 114. ],\n",
              "       [1943.8],\n",
              "       [2027.6],\n",
              "       [1269.6],\n",
              "       [  33.4],\n",
              "       [ 467. ],\n",
              "       [  18. ],\n",
              "       [ 143.6],\n",
              "       [ 375.8],\n",
              "       [1309.6],\n",
              "       [ 923.2],\n",
              "       [  86. ],\n",
              "       [ 423.8],\n",
              "       [ 317.2],\n",
              "       [ 467.2],\n",
              "       [  93.2],\n",
              "       [ 705.8],\n",
              "       [ 603.4],\n",
              "       [  25.4],\n",
              "       [ 808.2],\n",
              "       [ 173.2],\n",
              "       [ 591.2],\n",
              "       [ 605.6],\n",
              "       [  10.8],\n",
              "       [ 554. ],\n",
              "       [1294. ],\n",
              "       [1067.6],\n",
              "       [ 747.8],\n",
              "       [ 689.2],\n",
              "       [ 890.2],\n",
              "       [ 712.4],\n",
              "       [ 989.2],\n",
              "       [1574. ],\n",
              "       [1422. ],\n",
              "       [ 774.2],\n",
              "       [   8.8],\n",
              "       [ 198.2],\n",
              "       [ 770. ],\n",
              "       [  71.6],\n",
              "       [ 931. ],\n",
              "       [ 188.8],\n",
              "       [1178.2],\n",
              "       [ 276.8],\n",
              "       [ 640.8],\n",
              "       [ 584.4],\n",
              "       [ 893. ],\n",
              "       [ 139.4],\n",
              "       [ 167. ],\n",
              "       [  85.2],\n",
              "       [  72. ],\n",
              "       [ 786.6],\n",
              "       [1116.2],\n",
              "       [ 393. ],\n",
              "       [ 417. ],\n",
              "       [  24.8],\n",
              "       [ 196.4],\n",
              "       [ 886. ],\n",
              "       [ 121. ],\n",
              "       [ 305.8],\n",
              "       [ 467.2],\n",
              "       [ 293.2],\n",
              "       [ 342.4],\n",
              "       [ 145.4],\n",
              "       [ 375. ],\n",
              "       [ 189.8],\n",
              "       [ 767.4],\n",
              "       [ 570.4],\n",
              "       [ 937. ],\n",
              "       [ 314. ],\n",
              "       [ 505. ],\n",
              "       [1021.4],\n",
              "       [ 350.2],\n",
              "       [ 789.6],\n",
              "       [ 851.4],\n",
              "       [1090.4],\n",
              "       [  42.4],\n",
              "       [ 178.8],\n",
              "       [  19.2],\n",
              "       [1694.8],\n",
              "       [ 584.6],\n",
              "       [  34.8],\n",
              "       [ 994.4],\n",
              "       [ 488. ],\n",
              "       [ 758. ],\n",
              "       [1105.2],\n",
              "       [  80.4],\n",
              "       [1053.6],\n",
              "       [   8.8],\n",
              "       [ 455.8],\n",
              "       [ 351.8],\n",
              "       [ 320.6],\n",
              "       [ 222.2],\n",
              "       [  30.6],\n",
              "       [   8.8],\n",
              "       [  98.2],\n",
              "       [1096.2],\n",
              "       [1046.6],\n",
              "       [   8.8],\n",
              "       [ 714.4],\n",
              "       [ 358.2],\n",
              "       [ 624.6],\n",
              "       [ 438.4],\n",
              "       [ 502.8],\n",
              "       [  83.2],\n",
              "       [ 210.2],\n",
              "       [ 257.6],\n",
              "       [ 335.4],\n",
              "       [  78.8],\n",
              "       [ 646.6],\n",
              "       [  71.2],\n",
              "       [1449.4],\n",
              "       [1099.4],\n",
              "       [ 251. ],\n",
              "       [1228.6],\n",
              "       [1128.8],\n",
              "       [1056.8],\n",
              "       [ 362. ],\n",
              "       [ 132.8],\n",
              "       [  89.6],\n",
              "       [ 809.8],\n",
              "       [  58.6],\n",
              "       [1293.6],\n",
              "       [   8.8],\n",
              "       [ 408. ],\n",
              "       [  38.6],\n",
              "       [1154.4],\n",
              "       [ 354. ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HB1rQB7mvN8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the actual values for the test set.\n",
        "actual = test[y_column]\n",
        "\n",
        "# Compute the mean squared error of our predictions.\n",
        "mse = (((predictions - actual) ** 2).sum()) / len(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKjBHfm7vQ-r",
        "colab_type": "code",
        "outputId": "871990cf-2573-4b27-b637-0ff84f66210c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "mse"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pts    4501.658346\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    }
  ]
}